{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf res\n!rm -f cv_res.zip\n\n!mkdir res","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2 as cv\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import *\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom keras.utils.vis_utils import plot_model\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT = Path('/kaggle/input') / 'cv-final-project-data' / 'dataset'\nSEED = 0\nIMG_SIZE = 256\nBATCH_SIZE = 32\nlabels = ['bee', 'wasp', 'insect', 'flower']\ntable_data = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(str(ROOT / 'labels.csv'))\ndf['path'] = [row.replace('\\\\', os.sep) for row in df['path']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data(df, label, n_samples=5):\n    q = df[df['label'] == label]\n    samples = q.sample(n=n_samples)\n\n    fig, ax = plt.subplots(nrows=1, ncols=n_samples, figsize=(4*n_samples,4))\n    for i, path in enumerate(samples['path']):\n        img = cv.imread(str(ROOT / path), -1)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        ax[i].imshow(img)\n        ax[i].axis('off')\n    fig.suptitle(f'Label: {label}')\n    plt.savefig(f'res{os.sep}{label}.png', bbox_inches='tight')\n    plt.show()\n\n    n = len(q)\n    low = len(q[q['photo_quality'] == 0])\n    val = len(q[q['is_validation'] == 1])\n    test = len(q[q['is_final_validation'] == 1])\n    print(f'Total number of samples for {label}: {n}')\n    if label == 'bee' or label == 'wasp':\n        print(f'Number of low quality samples: {low}')\n        print(f'Number of high quality samples: {n - low}')\n    print(f'Number of training samples: {n - val - test}')\n    print(f'Number of validation samples: {val}')\n    print(f'Number of testing samples: {test}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_data(df, label=labels[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_data(df, label=labels[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_data(df, label=labels[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_data(df, label=labels[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.bar(labels, [len(df[df['label'] == label]) for label in labels])\nplt.title('Dataset size for each category')\nplt.xlabel('Category')\nplt.ylabel('Number of samples')\nplt.savefig(f'res{os.sep}bar_plot.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df[(df['is_validation'] == 0) & (df['is_final_validation'] == 0)].reset_index(drop=True)\nval_df = df[df['is_validation'] == 1].reset_index(drop=True)\ntest_df = df[df['is_final_validation'] == 1].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def create_datasets(df, img_size):\n#     imgs = []\n#     for path in tqdm(df['path']):\n#         img = cv.imread(str(ROOT / path))\n#         img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n#         img = cv.resize(img, (img_size,img_size))\n#         imgs.append(img)\n        \n#     imgs = np.array(imgs, dtype='float32')\n#     imgs = imgs / 255.0\n#     df = pd.get_dummies(df['label'])\n#     return imgs, df\n\n\n# train_imgs, train_df = create_datasets(train_df, IMG_SIZE)\n# val_imgs, val_df = create_datasets(val_df, IMG_SIZE)\n# test_imgs, test_df = create_datasets(test_df, IMG_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = preprocessing.image.ImageDataGenerator(rescale=1./255.)\n\ntrain_datagen = datagen.flow_from_dataframe(train_df, \n                                            directory=str(ROOT), \n                                            x_col='path', \n                                            y_col='label',\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            seed=SEED\n                                           ) \n\nval_datagen = datagen.flow_from_dataframe(val_df,\n                                            directory=str(ROOT), \n                                            x_col='path', \n                                            y_col='label',\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            seed=SEED\n                                           ) \n\ntest_datagen = datagen.flow_from_dataframe(test_df, \n                                           directory=str(ROOT), \n                                           x_col='path', \n                                           y_col='label',\n                                           target_size=(IMG_SIZE, IMG_SIZE),\n                                           seed=SEED\n                                           ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for directly loading on the memory\n# train_X = train_imgs\n# train_Y = train_df\n# validation_all = (val_imgs, val_df)\n# test_X = test_imgs\n# test_Y = test_df\n\n# for generators\ntrain_X = train_datagen\ntrain_Y = None\nvalidation_all = val_datagen\ntest_X = test_datagen\ntest_Y = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\npre_net = applications.ResNet50V2(input_shape=(IMG_SIZE, IMG_SIZE, 3), \n                                include_top=False)\nmodel.add(pre_net)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(4, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n              loss=losses.BinaryCrossentropy(),\n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file=f'res{os.sep}model1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es_callback = callbacks.EarlyStopping(patience=5, \n                                      verbose=1, \n                                      restore_best_weights=True)\n\nmobile_wo_train_hist = model.fit(x=train_X,\n                                 y=train_Y,\n                                 batch_size=BATCH_SIZE,\n                                 epochs=50, \n                                 validation_data=validation_all,\n                                 callbacks=[es_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(test_X, test_Y)\ntable_data.append(('ResNet', round(acc, 4), round(loss, 4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\npre_net = applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), \n                                   include_top=False)\nmodel.add(pre_net)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(4, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n              loss=losses.BinaryCrossentropy(),\n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file=f'res{os.sep}model2.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es_callback = callbacks.EarlyStopping(patience=5, \n                                      verbose=1, \n                                      restore_best_weights=True)\n\nmobile_w_train_hist = model.fit(x=train_X,\n                                y=train_Y,\n                                batch_size=BATCH_SIZE,\n                                epochs=50, \n                                validation_data=validation_all,\n                                callbacks=[es_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(test_X, test_Y)\ntable_data.append(('MobileNet', round(acc, 4), round(loss, 4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\nmodel.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D(3))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\nmodel.add(layers.MaxPooling2D(3))\nmodel.add(layers.Dropout(0.2))\n# model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n# model.add(layers.MaxPooling2D(3))\n# model.add(layers.Dropout(0.2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(4, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n              loss=losses.BinaryCrossentropy(),\n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file=f'res{os.sep}model3.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es_callback = callbacks.EarlyStopping(patience=5, \n                                      verbose=1, \n                                      restore_best_weights=True)\n\ncustom_cnn = model.fit(x=train_X,\n                       y=train_Y,\n                       batch_size=BATCH_SIZE,\n                       epochs=50, \n                       validation_data=validation_all,\n                       callbacks=[es_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(test_X, test_Y)\ntable_data.append(('Custom CNN', round(acc, 4), round(loss, 4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nplt.plot(mobile_wo_train_hist.history['accuracy'], label='ResNet train accuracy', linestyle='-', color='b')\nplt.plot(mobile_wo_train_hist.history['val_accuracy'], label='ResNet val accuracy', linestyle=':', color='b')\nplt.plot(mobile_w_train_hist.history['accuracy'], label='MobileNet train accuracy', linestyle='-', color='g')\nplt.plot(mobile_w_train_hist.history['val_accuracy'], label='MobileNet val accuracy', linestyle=':', color='g')\nplt.plot(custom_cnn.history['accuracy'], label='Custom CNN train accuracy', linestyle='-', color='r')\nplt.plot(custom_cnn.history['val_accuracy'], label='Custom CNN val accuracy', linestyle=':', color='r')\nplt.title('Training and validation accuracy')\nplt.xlabel('Number of epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig(f'res{os.sep}acc.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nplt.plot(mobile_wo_train_hist.history['loss'], label='ResNet train loss', linestyle='-', color='b')\nplt.plot(mobile_wo_train_hist.history['val_loss'], label='ResNet val loss', linestyle=':', color='b')\nplt.plot(mobile_w_train_hist.history['loss'], label='MobileNet train loss', linestyle='-', color='g')\nplt.plot(mobile_w_train_hist.history['val_loss'], label='MobileNet val loss', linestyle=':', color='g')\nplt.plot(custom_cnn.history['loss'], label='Custom CNN train loss', linestyle='-', color='r')\nplt.plot(custom_cnn.history['val_loss'], label='Custom CNN val loss', linestyle=':', color='r')\nplt.title('Training and validation loss')\nplt.xlabel('Number of epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig(f'res{os.sep}loss.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title='table'\ncols = ['Model', 'Test accuracy', 'Test loss']\n\nfig, ax = plt.subplots()\ntable = ax.table(cellText=table_data, colLabels=cols,\n                 cellLoc='center', loc='center')\ntable.auto_set_font_size(False)\ntable.set_fontsize(55)\ntable.scale(5, 15)\nax.axis('off')\nplt.savefig(f'res{os.sep}{title}.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r cv_res.zip res","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}